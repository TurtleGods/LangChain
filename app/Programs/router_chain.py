import re
from app.Programs.Agent import get_llm
from app.Programs.Chroma import get_chroma
from app.services.db_service import get_issue_by_key
from sqlalchemy import text
from langchain.chains import ConversationalRetrievalChain
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma 
from langchain_core.prompts.chat import(
    PromptTemplate
)
default_chain = None
chat_history=[]
async def issue_detail_chain(issue_key:str):
    issue = await get_issue_by_key(issue_key)
    if not issue:
        return f"âŒ æ²’æœ‰æ‰¾åˆ° {issue_key} çš„ç´°ç¯€"
    
    answer = (
        f"Issue {issue['key']} ç´°ç¯€ï¼š\n"
        f"- Summary: {issue.get('summary')}\n"
        f"- Description: {issue.get('description')}\n"
        f"- Status: {issue.get('status')}\n"
        f"- Assignee: {issue.get('assignee')}\n"
        f"- Created: {issue.get('created')}\n"
        f"- Updated: {issue.get('updated')}\n"
    )
    if issue.get("comments"):
        answer += "\nðŸ’¬ Comments:\n"
        for c in issue["comments"]:
            answer += f"- {c['author']} ({c['created']}): {c['body']}\n"
    return {"answer":answer}

async def similarity_chain(issue_key:str):
    issue = await get_issue_by_key(issue_key)
    if not issue:
        return  f"âŒ æ²’æ‰¾åˆ° {issue_key}"
    query_text = f"æ‰¾å’Œé€™å€‹{issue} Issue é¡žä¼¼çš„æ¡ˆä¾‹: {issue.get('summary')} {issue.get('description')}"
    result = default_chain.invoke({"question": query_text,"issue_key":issue_key, "chat_history": chat_history})
    return result


async def filter_chain(question:str):
    query_text = f"æ ¹æ“šjira issuesï¼Œæ‰¾å‡ºèˆ‡æ­¤å•é¡Œç›¸é—œçš„æ¡ˆä¾‹ï¼Œä¸¦ç¢ºèªcomment ä¸­æ˜¯å¦æœ‰è§£æ±ºæ–¹æ³•:{question}"
    result = default_chain.invoke({"question": query_text,"issue_key":"",  "chat_history": chat_history})
    return result

async def list_chain(question:str):
    query_text = f"åˆ—å‡ºæ‰€æœ‰èˆ‡ä»¥ä¸‹ä¸»é¡Œç›¸é—œçš„ Jira issuesï¼š{question}"
    result = default_chain.invoke({"question": query_text, "issue_key":"", "chat_history": chat_history})
    return result

# --- RouterChain ---
async def router_chain(question: str,query_type:str,issue_key):
    global chat_history,default_chain
    llm = get_llm()
    vectordb =await get_chroma()
    retriever = vectordb.as_retriever(search_type="similarity", search_kwargs={"k": 10})
    print("Load default_chain")
    default_chain = ConversationalRetrievalChain.from_llm(
        llm,
        retriever, 
        combine_docs_chain_kwargs={"prompt": get_system_prompt()},
        return_source_documents=True)

    print(f"ðŸ‘‰ Query type detected: {query_type}")

    if query_type == "detail":
        result = await issue_detail_chain(issue_key)
    elif query_type == "similarity":
        result = await similarity_chain(issue_key)
    elif query_type == "filter":
        result = await filter_chain(question)
    elif query_type == "list":
        result = await list_chain(question)
    else:
        result = default_chain.ainvoke({"question": question,"issue_key":"","chat_history":chat_history})

    return result["answer"]

def get_system_prompt()-> str:
    prompt = """
        You are a Jira issue assistant. You have access to Jira issues with fields:
        key, summary, description, status.
        When possible, include hyperlinks for each issue key (e.g. [YTHG-830](https://mayohumancapital.atlassian.net/browse/YTHG-830)).
        Context:
        {context}

        Question:
        {question}
    """
    return PromptTemplate.from_template(prompt)